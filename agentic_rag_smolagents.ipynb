{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/miniconda3/envs/agent/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "knowledge_base = datasets.load_dataset(\"m-ric/huggingface_doc\", split=\"train\")\n",
    "knowledge_base = knowledge_base.filter(lambda row: row[\"source\"].startswith(\"huggingface/transformers\"))\n",
    "\n",
    "source_docs = [\n",
    "    Document(page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"].split(\"/\")[1]})\n",
    "    for doc in knowledge_base\n",
    "]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    add_start_index=True,\n",
    "    strip_whitespace=True,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    ")\n",
    "docs_processed = text_splitter.split_documents(source_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agentic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import Tool\n",
    "\n",
    "class RetrieverTool(Tool):\n",
    "    name = \"retriever\"\n",
    "    description = \"Uses semantic search to retrieve the parts of transformers documentation that could be most relevant to answer your query.\"\n",
    "    inputs = {\n",
    "        \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The query to perform. This should be semantically close to your target documents. Use the affirmative form rather than a question.\",\n",
    "        }\n",
    "    }\n",
    "    output_type = \"string\"\n",
    "\n",
    "    def __init__(self, docs, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.retriever = BM25Retriever.from_documents(\n",
    "            docs, k=10\n",
    "        )\n",
    "\n",
    "    def forward(self, query: str) -> str:\n",
    "        assert isinstance(query, str), \"Your search query must be a string\"\n",
    "\n",
    "        docs = self.retriever.invoke(\n",
    "            query,\n",
    "        )\n",
    "        return \"\\nRetrieved documents:\\n\" + \"\".join(\n",
    "            [\n",
    "                f\"\\n\\n===== Document {str(i)} =====\\n\" + doc.page_content\n",
    "                for i, doc in enumerate(docs)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "retriever_tool = RetrieverTool(docs_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import HfApiModel, CodeAgent\n",
    "\n",
    "agent = CodeAgent(\n",
    "    tools=[retriever_tool], model=HfApiModel(), max_steps=4, verbosity_level=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">For a transformers model training, which is slower, the forward or the backward pass?</span>                           <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ HfApiModel - Qwen/Qwen2.5-Coder-32B-Instruct ──────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mFor a transformers model training, which is slower, the forward or the backward pass?\u001b[0m                           \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m HfApiModel - Qwen/Qwen2.5-Coder-32B-Instruct \u001b[0m\u001b[38;2;212;183;2m─────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold; font-style: italic\">Output message of the LLM:</span> <span style=\"color: #d4b702; text-decoration-color: #d4b702\">────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">Thought: To determine whether the forward or backward pass is slower in a transformers model training, I need to </span><span style=\"background-color: #0d1117\">  </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">retrieve information from the documentation about the training process. I will use the </span><span style=\"color: #a5d6ff; text-decoration-color: #a5d6ff; background-color: #0d1117\">`retriever`</span><span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\"> tool to fetch </span><span style=\"background-color: #0d1117\">  </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">relevant sections.</span><span style=\"background-color: #0d1117\">                                                                                                 </span>\n",
       "<span style=\"background-color: #0d1117\">                                                                                                                   </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">Code:</span><span style=\"background-color: #0d1117\">                                                                                                              </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">```py</span><span style=\"background-color: #0d1117\">                                                                                                              </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">forward_pass_info = retriever(query=\"transformers model forward pass\")</span><span style=\"background-color: #0d1117\">                                             </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">backward_pass_info = retriever(query=\"transformers model backward pass\")</span><span style=\"background-color: #0d1117\">                                           </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">print(\"Forward pass info:\", forward_pass_info)</span><span style=\"background-color: #0d1117\">                                                                     </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">print(\"Backward pass info:\", backward_pass_info)</span><span style=\"background-color: #0d1117\">                                                                   </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">```&lt;end_code&gt;</span><span style=\"background-color: #0d1117\">                                                                                                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3mOutput message of the LLM:\u001b[0m \u001b[38;2;212;183;2m────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mThought:\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mTo\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mdetermine\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mwhether\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mforward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mor\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mbackward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpass\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mis\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mslower\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23min\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23ma\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mtransformers\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mmodel\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mtraining,\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mI\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mneed\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mto\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[48;2;13;17;23m  \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mretrieve\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23minformation\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mfrom\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mdocumentation\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mabout\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mtraining\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mprocess.\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mI\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mwill\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23muse\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;165;214;255;48;2;13;17;23m`retriever`\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mtool\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mto\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mfetch\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[48;2;13;17;23m  \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mrelevant\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23msections.\u001b[0m\u001b[48;2;13;17;23m                                                                                                 \u001b[0m\n",
       "\u001b[48;2;13;17;23m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mCode:\u001b[0m\u001b[48;2;13;17;23m                                                                                                              \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23m```py\u001b[0m\u001b[48;2;13;17;23m                                                                                                              \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mforward_pass_info\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m=\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mretriever(query=\"transformers\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mmodel\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mforward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpass\")\u001b[0m\u001b[48;2;13;17;23m                                             \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mbackward_pass_info\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m=\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mretriever(query=\"transformers\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mmodel\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mbackward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpass\")\u001b[0m\u001b[48;2;13;17;23m                                           \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mprint(\"Forward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpass\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23minfo:\",\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mforward_pass_info)\u001b[0m\u001b[48;2;13;17;23m                                                                     \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mprint(\"Backward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpass\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23minfo:\",\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mbackward_pass_info)\u001b[0m\u001b[48;2;13;17;23m                                                                   \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23m```<end_code>\u001b[0m\u001b[48;2;13;17;23m                                                                                                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">forward_pass_info </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> retriever(query</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"transformers model forward pass\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                         </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">backward_pass_info </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> retriever(query</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"transformers model backward pass\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                       </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"Forward pass info:\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, forward_pass_info)</span><span style=\"background-color: #272822\">                                                                 </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"Backward pass info:\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, backward_pass_info)</span><span style=\"background-color: #272822\">                                                               </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mforward_pass_info\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mretriever\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mtransformers model forward pass\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                         \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mbackward_pass_info\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mretriever\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mtransformers model backward pass\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                       \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mForward pass info:\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mforward_pass_info\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                 \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mBackward pass info:\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mbackward_pass_info\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                               \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Execution logs:</span>\n",
       "Forward pass info: \n",
       "Retrieved documents:\n",
       "\n",
       "\n",
       "===== Document 0 =====\n",
       "model_inputs = tokenizer(src_text, text_target=tgt_text, return_tensors=\"pt\")\n",
       "\n",
       "model(**model_inputs)  # forward pass\n",
       "```\n",
       "\n",
       "- Generation\n",
       "\n",
       "===== Document 1 =====\n",
       "&gt;&gt;&gt; model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-en-ro\")\n",
       "&gt;&gt;&gt; # forward pass\n",
       "&gt;&gt;&gt; model(**inputs)\n",
       "```\n",
       "\n",
       "- Generation\n",
       "\n",
       "  While generating the target text set the `decoder_start_token_id` to the target language id. The following\n",
       "  example shows how to translate English to Romanian using the *facebook/mbart-large-en-ro* model.\n",
       "\n",
       "```python\n",
       "&gt;&gt;&gt; from transformers import MBartForConditionalGeneration, MBartTokenizer\n",
       "\n",
       "===== Document 2 =====\n",
       "```python\n",
       "from transformers import Tool\n",
       "\n",
       "\n",
       "class HFModelDownloadsTool(Tool):\n",
       "    pass\n",
       "```\n",
       "\n",
       "===== Document 3 =====\n",
       "Next, regarding the debugging strategy, there are generally a few from which to choose from:\n",
       "\n",
       "- Decompose the original model into many small testable components and run a forward pass on each of those for\n",
       "  verification\n",
       "- Decompose the original model only into the original *tokenizer* and the original *model*, run a forward pass on\n",
       "  those, and use intermediate print statements or breakpoints for verification\n",
       "\n",
       "===== Document 4 =====\n",
       "Next, regarding the debugging strategy, there are generally a few from\n",
       "which to choose from:\n",
       "\n",
       "-   Decompose the original model into many small testable components and\n",
       "    run a forward pass on each of those for verification\n",
       "-   Decompose the original model only into the original *tokenizer* and\n",
       "    the original *model*, run a forward pass on those, and use\n",
       "    intermediate print statements or breakpoints for verification\n",
       "\n",
       "===== Document 5 =====\n",
       "layer is falsely activated during the forward pass, *i.e.* pass *self.training* to [PyTorch's functional \n",
       "dropout](https://pytorch.org/docs/stable/nn.functional.html?highlight=dropout#torch.nn.functional.dropout)\n",
       "\n",
       "===== Document 6 =====\n",
       "- For languages with a Roman alphabet, such as English or French, the tokenizer can be used directly to \n",
       "pre-process the text inputs. The following code example runs a forward pass using the MMS-TTS English checkpoint:\n",
       "\n",
       "```python\n",
       "import torch\n",
       "from transformers import VitsTokenizer, VitsModel, set_seed\n",
       "\n",
       "tokenizer = VitsTokenizer.from_pretrained(\"facebook/mms-tts-eng\")\n",
       "model = VitsModel.from_pretrained(\"facebook/mms-tts-eng\")\n",
       "\n",
       "===== Document 7 =====\n",
       "Having managed to correctly load the pretrained weights into the 🤗 Transformers implementation, you should now \n",
       "make\n",
       "sure that the forward pass is correctly implemented. In [Get familiar with the original \n",
       "repository](#34-run-a-pretrained-checkpoint-using-the-original-repository), you have already created a script that \n",
       "runs a forward\n",
       "pass of the model using the original repository. Now you should write an analogous script using the 🤗 Transformers\n",
       "\n",
       "===== Document 8 =====\n",
       "4.  [ ] Created script that successfully runs forward pass using\n",
       "    original repository and checkpoint\n",
       "\n",
       "5.  [ ] Successfully opened a PR and added the model skeleton to Transformers\n",
       "\n",
       "6.  [ ] Successfully converted original checkpoint to Transformers\n",
       "    checkpoint\n",
       "\n",
       "7.  [ ] Successfully ran forward pass in Transformers that gives\n",
       "    identical output to original checkpoint\n",
       "\n",
       "8.  [ ] Finished model tests in Transformers\n",
       "\n",
       "9.  [ ] Successfully added Tokenizer in Transformers\n",
       "\n",
       "===== Document 9 =====\n",
       "4.  [ ] Created script that successfully runs forward pass using\n",
       "    original repository and checkpoint\n",
       "\n",
       "5.  [ ] Successfully opened a PR and added the model skeleton to Transformers\n",
       "\n",
       "6.  [ ] Successfully converted original checkpoint to Transformers\n",
       "    checkpoint\n",
       "\n",
       "7.  [ ] Successfully ran forward pass in Transformers that gives\n",
       "    identical output to original checkpoint\n",
       "\n",
       "8.  [ ] Finished model tests in Transformers\n",
       "\n",
       "9.  [ ] Successfully added Tokenizer in Transformers\n",
       "Backward pass info: \n",
       "Retrieved documents:\n",
       "\n",
       "\n",
       "===== Document 0 =====\n",
       "Saving all activations from the forward pass in order to compute the gradients during the backward pass can result \n",
       "in \n",
       "significant memory overhead. The alternative approach of discarding the activations and recalculating them when \n",
       "needed \n",
       "during the backward pass, would introduce a considerable computational overhead and slow down the training process.\n",
       "\n",
       "===== Document 1 =====\n",
       "- A train step function which combines the loss function and optimizer update, does the forward and backward pass \n",
       "and returns the updated parameters.\n",
       "\n",
       "===== Document 2 =====\n",
       "```python\n",
       "from transformers import Tool\n",
       "\n",
       "\n",
       "class HFModelDownloadsTool(Tool):\n",
       "    pass\n",
       "```\n",
       "\n",
       "===== Document 3 =====\n",
       "For convolutions and linear layers there are 2x flops in the backward compared to the forward, which generally \n",
       "translates \n",
       "into ~2x slower (sometimes more, because sizes in the backward tend to be more awkward). Activations are usually \n",
       "bandwidth-limited, and it’s typical for an activation to have to read more data in the backward than in the forward\n",
       "(e.g. activation forward reads once, writes once, activation backward reads twice, gradOutput and output of the \n",
       "forward,\n",
       "\n",
       "===== Document 4 =====\n",
       "overhead. This is super helpful when you have activation checkpointing enabled, where we do a forward recompute and\n",
       "backward passes a single layer granularity and want to keep the parameter in the forward recompute till the \n",
       "backward\n",
       "\n",
       "===== Document 5 =====\n",
       "```py\n",
       "&gt;&gt;&gt; from transformers import AutoTokenizer\n",
       "\n",
       "&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
       "```\n",
       "\n",
       "Then pass your text to the tokenizer:\n",
       "\n",
       "===== Document 6 =====\n",
       "Depending on your task, you'll typically pass the following parameters to [`Trainer`]:\n",
       "\n",
       "1. You'll start with a [`PreTrainedModel`] or a \n",
       "[`torch.nn.Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module):\n",
       "\n",
       "   ```py\n",
       "   &gt;&gt;&gt; from transformers import AutoModelForSequenceClassification\n",
       "\n",
       "   &gt;&gt;&gt; model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
       "   ```\n",
       "\n",
       "===== Document 7 =====\n",
       "## How to benchmark 🤗 Transformers models\n",
       "\n",
       "The classes [`PyTorchBenchmark`] and [`TensorFlowBenchmark`] allow to flexibly benchmark 🤗 Transformers models. \n",
       "The benchmark classes allow us to measure the _peak memory usage_ and _required time_ for both _inference_ and \n",
       "_training_.\n",
       "\n",
       "&lt;Tip&gt;\n",
       "\n",
       "Hereby, _inference_ is defined by a single forward pass, and _training_ is defined by a single forward pass and\n",
       "backward pass.\n",
       "\n",
       "&lt;/Tip&gt;\n",
       "\n",
       "===== Document 8 =====\n",
       "&lt;/hfoption&gt;\n",
       "&lt;/hfoptions&gt;\n",
       "\n",
       "To enable FlashAttention-2, pass the argument `attn_implementation=\"flash_attention_2\"` to \n",
       "[`~AutoModelForCausalLM.from_pretrained`]:\n",
       "\n",
       "```python\n",
       "import torch\n",
       "from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaForCausalLM\n",
       "\n",
       "model_id = \"tiiuae/falcon-7b\"\n",
       "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
       "\n",
       "model = AutoModelForCausalLM.from_pretrained(\n",
       "    model_id, \n",
       "    torch_dtype=torch.bfloat16, \n",
       "    attn_implementation=\"flash_attention_2\",\n",
       ")\n",
       "```\n",
       "\n",
       "&lt;Tip&gt;\n",
       "\n",
       "===== Document 9 =====\n",
       "- Avoid storing the intermediate results of each layer by using reversible transformer layers to obtain them during\n",
       "the backward pass (subtracting the residuals from the input of the next layer gives them back) or recomputing them \n",
       "for results inside a given layer (less efficient than storing them but saves memory).\n",
       "- Compute the feedforward operations by chunks and not on the whole batch.\n",
       "\n",
       "Out: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mExecution logs:\u001b[0m\n",
       "Forward pass info: \n",
       "Retrieved documents:\n",
       "\n",
       "\n",
       "===== Document 0 =====\n",
       "model_inputs = tokenizer(src_text, text_target=tgt_text, return_tensors=\"pt\")\n",
       "\n",
       "model(**model_inputs)  # forward pass\n",
       "```\n",
       "\n",
       "- Generation\n",
       "\n",
       "===== Document 1 =====\n",
       ">>> model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-en-ro\")\n",
       ">>> # forward pass\n",
       ">>> model(**inputs)\n",
       "```\n",
       "\n",
       "- Generation\n",
       "\n",
       "  While generating the target text set the `decoder_start_token_id` to the target language id. The following\n",
       "  example shows how to translate English to Romanian using the *facebook/mbart-large-en-ro* model.\n",
       "\n",
       "```python\n",
       ">>> from transformers import MBartForConditionalGeneration, MBartTokenizer\n",
       "\n",
       "===== Document 2 =====\n",
       "```python\n",
       "from transformers import Tool\n",
       "\n",
       "\n",
       "class HFModelDownloadsTool(Tool):\n",
       "    pass\n",
       "```\n",
       "\n",
       "===== Document 3 =====\n",
       "Next, regarding the debugging strategy, there are generally a few from which to choose from:\n",
       "\n",
       "- Decompose the original model into many small testable components and run a forward pass on each of those for\n",
       "  verification\n",
       "- Decompose the original model only into the original *tokenizer* and the original *model*, run a forward pass on\n",
       "  those, and use intermediate print statements or breakpoints for verification\n",
       "\n",
       "===== Document 4 =====\n",
       "Next, regarding the debugging strategy, there are generally a few from\n",
       "which to choose from:\n",
       "\n",
       "-   Decompose the original model into many small testable components and\n",
       "    run a forward pass on each of those for verification\n",
       "-   Decompose the original model only into the original *tokenizer* and\n",
       "    the original *model*, run a forward pass on those, and use\n",
       "    intermediate print statements or breakpoints for verification\n",
       "\n",
       "===== Document 5 =====\n",
       "layer is falsely activated during the forward pass, *i.e.* pass *self.training* to [PyTorch's functional \n",
       "dropout](https://pytorch.org/docs/stable/nn.functional.html?highlight=dropout#torch.nn.functional.dropout)\n",
       "\n",
       "===== Document 6 =====\n",
       "- For languages with a Roman alphabet, such as English or French, the tokenizer can be used directly to \n",
       "pre-process the text inputs. The following code example runs a forward pass using the MMS-TTS English checkpoint:\n",
       "\n",
       "```python\n",
       "import torch\n",
       "from transformers import VitsTokenizer, VitsModel, set_seed\n",
       "\n",
       "tokenizer = VitsTokenizer.from_pretrained(\"facebook/mms-tts-eng\")\n",
       "model = VitsModel.from_pretrained(\"facebook/mms-tts-eng\")\n",
       "\n",
       "===== Document 7 =====\n",
       "Having managed to correctly load the pretrained weights into the 🤗 Transformers implementation, you should now \n",
       "make\n",
       "sure that the forward pass is correctly implemented. In [Get familiar with the original \n",
       "repository](#34-run-a-pretrained-checkpoint-using-the-original-repository), you have already created a script that \n",
       "runs a forward\n",
       "pass of the model using the original repository. Now you should write an analogous script using the 🤗 Transformers\n",
       "\n",
       "===== Document 8 =====\n",
       "4.  [ ] Created script that successfully runs forward pass using\n",
       "    original repository and checkpoint\n",
       "\n",
       "5.  [ ] Successfully opened a PR and added the model skeleton to Transformers\n",
       "\n",
       "6.  [ ] Successfully converted original checkpoint to Transformers\n",
       "    checkpoint\n",
       "\n",
       "7.  [ ] Successfully ran forward pass in Transformers that gives\n",
       "    identical output to original checkpoint\n",
       "\n",
       "8.  [ ] Finished model tests in Transformers\n",
       "\n",
       "9.  [ ] Successfully added Tokenizer in Transformers\n",
       "\n",
       "===== Document 9 =====\n",
       "4.  [ ] Created script that successfully runs forward pass using\n",
       "    original repository and checkpoint\n",
       "\n",
       "5.  [ ] Successfully opened a PR and added the model skeleton to Transformers\n",
       "\n",
       "6.  [ ] Successfully converted original checkpoint to Transformers\n",
       "    checkpoint\n",
       "\n",
       "7.  [ ] Successfully ran forward pass in Transformers that gives\n",
       "    identical output to original checkpoint\n",
       "\n",
       "8.  [ ] Finished model tests in Transformers\n",
       "\n",
       "9.  [ ] Successfully added Tokenizer in Transformers\n",
       "Backward pass info: \n",
       "Retrieved documents:\n",
       "\n",
       "\n",
       "===== Document 0 =====\n",
       "Saving all activations from the forward pass in order to compute the gradients during the backward pass can result \n",
       "in \n",
       "significant memory overhead. The alternative approach of discarding the activations and recalculating them when \n",
       "needed \n",
       "during the backward pass, would introduce a considerable computational overhead and slow down the training process.\n",
       "\n",
       "===== Document 1 =====\n",
       "- A train step function which combines the loss function and optimizer update, does the forward and backward pass \n",
       "and returns the updated parameters.\n",
       "\n",
       "===== Document 2 =====\n",
       "```python\n",
       "from transformers import Tool\n",
       "\n",
       "\n",
       "class HFModelDownloadsTool(Tool):\n",
       "    pass\n",
       "```\n",
       "\n",
       "===== Document 3 =====\n",
       "For convolutions and linear layers there are 2x flops in the backward compared to the forward, which generally \n",
       "translates \n",
       "into ~2x slower (sometimes more, because sizes in the backward tend to be more awkward). Activations are usually \n",
       "bandwidth-limited, and it’s typical for an activation to have to read more data in the backward than in the forward\n",
       "(e.g. activation forward reads once, writes once, activation backward reads twice, gradOutput and output of the \n",
       "forward,\n",
       "\n",
       "===== Document 4 =====\n",
       "overhead. This is super helpful when you have activation checkpointing enabled, where we do a forward recompute and\n",
       "backward passes a single layer granularity and want to keep the parameter in the forward recompute till the \n",
       "backward\n",
       "\n",
       "===== Document 5 =====\n",
       "```py\n",
       ">>> from transformers import AutoTokenizer\n",
       "\n",
       ">>> tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
       "```\n",
       "\n",
       "Then pass your text to the tokenizer:\n",
       "\n",
       "===== Document 6 =====\n",
       "Depending on your task, you'll typically pass the following parameters to [`Trainer`]:\n",
       "\n",
       "1. You'll start with a [`PreTrainedModel`] or a \n",
       "[`torch.nn.Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module):\n",
       "\n",
       "   ```py\n",
       "   >>> from transformers import AutoModelForSequenceClassification\n",
       "\n",
       "   >>> model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
       "   ```\n",
       "\n",
       "===== Document 7 =====\n",
       "## How to benchmark 🤗 Transformers models\n",
       "\n",
       "The classes [`PyTorchBenchmark`] and [`TensorFlowBenchmark`] allow to flexibly benchmark 🤗 Transformers models. \n",
       "The benchmark classes allow us to measure the _peak memory usage_ and _required time_ for both _inference_ and \n",
       "_training_.\n",
       "\n",
       "<Tip>\n",
       "\n",
       "Hereby, _inference_ is defined by a single forward pass, and _training_ is defined by a single forward pass and\n",
       "backward pass.\n",
       "\n",
       "</Tip>\n",
       "\n",
       "===== Document 8 =====\n",
       "</hfoption>\n",
       "</hfoptions>\n",
       "\n",
       "To enable FlashAttention-2, pass the argument `attn_implementation=\"flash_attention_2\"` to \n",
       "[`~AutoModelForCausalLM.from_pretrained`]:\n",
       "\n",
       "```python\n",
       "import torch\n",
       "from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaForCausalLM\n",
       "\n",
       "model_id = \"tiiuae/falcon-7b\"\n",
       "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
       "\n",
       "model = AutoModelForCausalLM.from_pretrained(\n",
       "    model_id, \n",
       "    torch_dtype=torch.bfloat16, \n",
       "    attn_implementation=\"flash_attention_2\",\n",
       ")\n",
       "```\n",
       "\n",
       "<Tip>\n",
       "\n",
       "===== Document 9 =====\n",
       "- Avoid storing the intermediate results of each layer by using reversible transformer layers to obtain them during\n",
       "the backward pass (subtracting the residuals from the input of the next layer gives them back) or recomputing them \n",
       "for results inside a given layer (less efficient than storing them but saves memory).\n",
       "- Compute the feedforward operations by chunks and not on the whole batch.\n",
       "\n",
       "Out: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 6.05 seconds| Input tokens: 2,102 | Output tokens: 105]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 6.05 seconds| Input tokens: 2,102 | Output tokens: 105]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m2\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold; font-style: italic\">Output message of the LLM:</span> <span style=\"color: #d4b702; text-decoration-color: #d4b702\">────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">Thought: From the retrieved information, it seems the backward pass is generally slower than the forward pass. </span><span style=\"background-color: #0d1117\">    </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">Specifically, Document 3 mentions that there are ~2x more floating-point operations (flops) in the backward pass </span><span style=\"background-color: #0d1117\">  </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">compared to the forward pass for layers like convolutions and linear layers. Document 0 also mentions that saving </span><span style=\"background-color: #0d1117\"> </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">activations for the backward pass can result in significant memory overhead.</span><span style=\"background-color: #0d1117\">                                       </span>\n",
       "<span style=\"background-color: #0d1117\">                                                                                                                   </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">Given this information, I will proceed to confirm the information and conclude that the backward pass is slower.</span><span style=\"background-color: #0d1117\">   </span>\n",
       "<span style=\"background-color: #0d1117\">                                                                                                                   </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">Code:</span><span style=\"background-color: #0d1117\">                                                                                                              </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">```py</span><span style=\"background-color: #0d1117\">                                                                                                              </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">final_answer(\"backward pass\")</span><span style=\"background-color: #0d1117\">                                                                                      </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">```&lt;end_code&gt;</span><span style=\"background-color: #0d1117\">                                                                                                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3mOutput message of the LLM:\u001b[0m \u001b[38;2;212;183;2m────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mThought:\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mFrom\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mretrieved\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23minformation,\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mit\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mseems\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mbackward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpass\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mis\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mgenerally\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mslower\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthan\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mforward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpass.\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[48;2;13;17;23m    \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mSpecifically,\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mDocument\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m3\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mmentions\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthat\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthere\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mare\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m~2x\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mmore\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mfloating-point\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23moperations\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m(flops)\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23min\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mbackward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpass\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[48;2;13;17;23m  \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mcompared\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mto\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mforward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpass\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mfor\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mlayers\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mlike\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mconvolutions\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mand\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mlinear\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mlayers.\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mDocument\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m0\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23malso\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mmentions\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthat\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23msaving\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[48;2;13;17;23m \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mactivations\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mfor\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mbackward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpass\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mcan\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mresult\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23min\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23msignificant\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mmemory\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23moverhead.\u001b[0m\u001b[48;2;13;17;23m                                       \u001b[0m\n",
       "\u001b[48;2;13;17;23m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mGiven\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthis\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23minformation,\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mI\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mwill\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mproceed\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mto\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mconfirm\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23minformation\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mand\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mconclude\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthat\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mbackward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpass\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mis\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mslower.\u001b[0m\u001b[48;2;13;17;23m   \u001b[0m\n",
       "\u001b[48;2;13;17;23m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mCode:\u001b[0m\u001b[48;2;13;17;23m                                                                                                              \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23m```py\u001b[0m\u001b[48;2;13;17;23m                                                                                                              \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mfinal_answer(\"backward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpass\")\u001b[0m\u001b[48;2;13;17;23m                                                                                      \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23m```<end_code>\u001b[0m\u001b[48;2;13;17;23m                                                                                                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">final_answer(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"backward pass\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                                                  </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mfinal_answer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mbackward pass\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                  \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Out - Final answer: backward pass</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;212;183;2mOut - Final answer: backward pass\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 2: Duration 6.79 seconds| Input tokens: 6,002 | Output tokens: 218]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 2: Duration 6.79 seconds| Input tokens: 6,002 | Output tokens: 218]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output:\n",
      "backward pass\n"
     ]
    }
   ],
   "source": [
    "agent_output = agent.run(\"For a transformers model training, which is slower, the forward or the backward pass?\")\n",
    "\n",
    "print(\"Final output:\")\n",
    "print(agent_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
